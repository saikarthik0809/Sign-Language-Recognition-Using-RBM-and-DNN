This script implements a machine learning pipeline for classifying American Sign Language (ASL) images. It begins by loading and preprocessing the image dataset from a specified directory, converting images to 32x32 pixels, and normalizing the pixel values. Labels are encoded using `LabelEncoder`. The dataset is then split into training and testing sets. To handle class imbalance, class weights are calculated. A Bernoulli Restricted Boltzmann Machine (RBM) is used for feature extraction. The extracted features are fed into a deep neural network (DNN) with multiple dense layers, culminating in a softmax output layer for multi-class classification. The model is compiled and trained with class weights for 100 epochs. Post-training, the model is saved, and its performance is evaluated using accuracy, precision, recall, and confusion matrix metrics. The script also includes visualizations for training loss, accuracy, and the confusion matrix to aid in performance analysis.
